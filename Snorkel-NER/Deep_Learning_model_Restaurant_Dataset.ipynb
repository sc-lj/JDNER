{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IvraAQEm8the"
      },
      "source": [
        "# Restaurant Dataset - Deep Learning Model (BiLSTM) with Elmo pre-trained embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y96Xmew6845Q"
      },
      "source": [
        "Importing necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oBwfOtK3b-t_"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Input\n",
        "from keras.layers.merge import add\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uQkm1GGb2M_9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
            "Collecting seqeval\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s eta 0:00:011\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /home/lujun/anaconda3/envs/text/lib/python3.7/site-packages (from seqeval) (1.19.0)\n",
            "Collecting scikit-learn>=0.21.3\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/bd/05/e561bc99a615b5c099c7a9355409e5e57c525a108f1c2e156abb005b90a6/scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 11.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading https://mirrors.aliyun.com/pypi/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /home/lujun/anaconda3/envs/text/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/lujun/anaconda3/envs/text/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=95ccb1d003b32c63db2cc96a1d6c22d9aa91c66b256a25940ba4f0cd6f56debe\n",
            "  Stored in directory: /home/lujun/.cache/pip/wheels/71/b4/9b/3caba6a5308e31516acd63e3a07c5887cec85f1f9d909d3d59\n",
            "Successfully built seqeval\n",
            "Installing collected packages: threadpoolctl, scikit-learn, seqeval\n",
            "Successfully installed scikit-learn-1.0.2 seqeval-1.2.2 threadpoolctl-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UOVqjZiW89JC"
      },
      "source": [
        "Here, I initialize the tensorflow session and import Elmo pre-trainied embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "K4R_pLJ4cKjq"
      },
      "outputs": [],
      "source": [
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IgsCcFPB9DJg"
      },
      "source": [
        "**Preprocessing the data file to make the required dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FEV1CFxzcUr1"
      },
      "outputs": [],
      "source": [
        "def ret_df_file(file):\n",
        "    with open(file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        size = len(lines) \n",
        "        idx_list = [idx + 1 for idx, val in\n",
        "                enumerate(lines) if val == '\\n'] \n",
        "        res = [lines[i: j-1] for i, j in\n",
        "            zip([0] + idx_list, idx_list + \n",
        "            ([size] if idx_list[-1] != size else []))] \n",
        "        queries = ['' for i in range(len(res))]\n",
        "        tags = []\n",
        "        unigrams = []\n",
        "        for i, ele in enumerate(res):\n",
        "            for j, actual_str in enumerate(ele):\n",
        "                res[i][j] = actual_str.split('\\t')\n",
        "                res[i][j][-1] = res[i][j][-1].replace('\\n', '')\n",
        "                tags.append(res[i][j][0])\n",
        "                if j!=0:\n",
        "                    queries[i] = queries[i] + ' ' + res[i][j][-1]\n",
        "                else:\n",
        "                    queries[i] = res[i][j][-1]\n",
        "                unigrams.append(res[i][j][-1])\n",
        "    df_queries = []\n",
        "    pos = []\n",
        "    for i, ele in enumerate(res):\n",
        "        for j, actual_str in enumerate(ele):\n",
        "            df_queries.append(\"Sentence: \"+str(i))\n",
        "            pos.append(j)\n",
        "    return pd.DataFrame({\"Word\": unigrams, \"Tag\": tags, \"Query\": df_queries})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "A6emLxb7du6f"
      },
      "outputs": [],
      "source": [
        "df_train = ret_df_file(\"restauranttrain.bio\")\n",
        "df_test = ret_df_file(\"restauranttest.bio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "colab_type": "code",
        "id": "RAd-i141d5gL",
        "outputId": "bc9dde84-8283-4a25-b78c-a0db4f6d2aa4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>B-Rating</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>start</td>\n",
              "      <td>I-Rating</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>restaurants</td>\n",
              "      <td>O</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>with</td>\n",
              "      <td>O</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>inside</td>\n",
              "      <td>B-Amenity</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word        Tag        Query\n",
              "0            2   B-Rating  Sentence: 0\n",
              "1        start   I-Rating  Sentence: 0\n",
              "2  restaurants          O  Sentence: 0\n",
              "3         with          O  Sentence: 0\n",
              "4       inside  B-Amenity  Sentence: 0"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "1qV2C4Kdd6lZ",
        "outputId": "623661ff-17a4-4cc8-d4df-e412fd7aa97e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3805"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = set(list(df_train['Word'].values))\n",
        "words.add('PADword')\n",
        "n_words = len(words)\n",
        "n_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "H3bBtTVOf-B4",
        "outputId": "d4e213c0-7331-4ebc-c7cc-d6af2e4cc37e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags = list(set(df_train[\"Tag\"].values))\n",
        "n_tags = len(tags)\n",
        "n_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g7S38rvi9I19"
      },
      "source": [
        "**Function for getting each query and making a batch for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tBwR8W7hgC6n"
      },
      "outputs": [],
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Query\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "STdusIb6go44",
        "outputId": "378b7055-9a2f-45c9-9d5f-3e1cbb7d4439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('34', 'O')]\n"
          ]
        }
      ],
      "source": [
        "getter = SentenceGetter(df_train)\n",
        "sent = getter.get_next()\n",
        "print(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "wSt8-aU-gq_E",
        "outputId": "82eebe09-8d10-4b8b-ca93-7c92aeef0d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7660\n"
          ]
        }
      ],
      "source": [
        "sentences = getter.sentences\n",
        "print(len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "yyZwA8zfgw5G",
        "outputId": "c26081ba-3c40-4982-d450-6ccac48a8e3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "biggest sentence has 35 words\n"
          ]
        }
      ],
      "source": [
        "\n",
        "largest_sen = max(len(sen) for sen in sentences)\n",
        "print('biggest sentence has {} words'.format(largest_sen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZIYIqAIA9Sm6"
      },
      "source": [
        "**Looking at the frequency of the number of words in the queries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "colab_type": "code",
        "id": "mrUZjn1GhQKC",
        "outputId": "1e8733d9-441b-4cb6-d1ba-c43324644d80"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "plt.hist([len(sen) for sen in sentences], bins= 50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "mDzu98a7hSeX",
        "outputId": "e9f36601-3769-46d9-9870-202ba32ea18b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2228\n",
            "11\n"
          ]
        }
      ],
      "source": [
        "words2index = {w:i for i,w in enumerate(words)}\n",
        "tags2index = {t:i for i,t in enumerate(tags)}\n",
        "print(words2index['my'])\n",
        "print(tags2index['B-Location'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "colab_type": "code",
        "id": "-DH1wkFGhVha",
        "outputId": "26f99002-e483-4b36-de22-604df1be863a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['could',\n",
              " 'you',\n",
              " 'find',\n",
              " 'me',\n",
              " 'a',\n",
              " 'high',\n",
              " 'end',\n",
              " 'halal',\n",
              " 'restaurant',\n",
              " 'open',\n",
              " 'until',\n",
              " '12',\n",
              " 'pm',\n",
              " 'PADword',\n",
              " 'PADword']"
            ]
          },
          "execution_count": 63,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len = 15\n",
        "X = [[w[0]for w in s] for s in sentences]\n",
        "new_X = []\n",
        "for seq in X:\n",
        "    new_seq = []\n",
        "    for i in range(max_len):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"PADword\")\n",
        "    new_X.append(new_seq)\n",
        "new_X[15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IhEAvNLU9cgR"
      },
      "source": [
        "**Padding all the sequences to a length of 15** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "lTXYVgXkhgLo",
        "outputId": "8f2026e5-1b3e-4449-f939-4e172bf551c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3,  3,  3,  3,  3,  3,  3,  1,  3, 16,  0,  0,  0,  3,  3],\n",
              "      dtype=int32)"
            ]
          },
          "execution_count": 64,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = [[tags2index[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])\n",
        "y[15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lShcZVwo9ioU"
      },
      "source": [
        "**Spliting the data in train and test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sBKe847WhqSO"
      },
      "outputs": [],
      "source": [
        "X_tr, X_te, y_tr, y_te = train_test_split(new_X, y, test_size=0.1, random_state=2018)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kZ0lHrOB9ptH"
      },
      "source": [
        "**Defining the structure of the Elmo embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8aufo_mnhz7m"
      },
      "outputs": [],
      "source": [
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\n",
        "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
        "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
        "                      },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ljsdoawf96d-"
      },
      "source": [
        "**Defining the model architecture with BiLSTMs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "l85M9zfbh4hz",
        "outputId": "1660e245-cda8-440f-966a-f4a587db46ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        }
      ],
      "source": [
        "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
        "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
        "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
        "x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BiY-Gv5Ih76Z"
      },
      "outputs": [],
      "source": [
        "model = Model(input_text, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uTYD8SpEh-zk"
      },
      "outputs": [],
      "source": [
        "X_tr, X_val = X_tr[:190*batch_size], X_tr[-25*batch_size:]\n",
        "y_tr, y_val = y_tr[:190*batch_size], y_tr[-25*batch_size:]\n",
        "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
        "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ALu7Y1P-CpG"
      },
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "colab_type": "code",
        "id": "shlqmhiciA0l",
        "outputId": "96b6d03c-fa70-4974-9774-6f4185445ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 6080 samples, validate on 800 samples\n",
            "Epoch 1/3\n",
            "6080/6080 [==============================] - 970s 160ms/step - loss: 0.4223 - acc: 0.8827 - val_loss: 0.2803 - val_acc: 0.9147\n",
            "Epoch 2/3\n",
            "6080/6080 [==============================] - 955s 157ms/step - loss: 0.2461 - acc: 0.9261 - val_loss: 0.2646 - val_acc: 0.9213\n",
            "Epoch 3/3\n",
            "6080/6080 [==============================] - 953s 157ms/step - loss: 0.1992 - acc: 0.9379 - val_loss: 0.2620 - val_acc: 0.9227\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),\n",
        "                    batch_size=batch_size, epochs=3, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PvQ4vwv6-Jxi"
      },
      "source": [
        "**Checking the performance of the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "4KeRXdDAiCvv",
        "outputId": "2f95bc0c-84da-479f-8036-7bb1a04a2bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "736/736 [==============================] - 73s 99ms/step\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "X_te = X_te[:23*batch_size]\n",
        "test_pred = model.predict(np.array(X_te), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rwQINrJoib_N"
      },
      "outputs": [],
      "source": [
        "\n",
        "idx2tag = {i: w for w, i in tags2index.items()}\n",
        "\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "def test2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "    \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = test2label(y_te[:23*32])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tyy_SEtP-WCX"
      },
      "source": [
        "**Looking at the classification report for the model predictions on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "colab_type": "code",
        "id": "NBol2gK2icOn",
        "outputId": "c1a0efa2-be20-452e-c079-713ce71891d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score: 69.2%\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        Cuisine       0.82      0.78      0.80       304\n",
            "       Location       0.73      0.74      0.74       376\n",
            "        Amenity       0.57      0.41      0.47       256\n",
            "           Dish       0.60      0.66      0.63       133\n",
            "         Rating       0.67      0.73      0.70       101\n",
            "          Hours       0.61      0.57      0.59        90\n",
            "Restaurant_Name       0.77      0.77      0.77       177\n",
            "          Price       0.80      0.70      0.75        64\n",
            "\n",
            "      micro avg       0.71      0.68      0.69      1501\n",
            "      macro avg       0.71      0.68      0.69      1501\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
        "print(classification_report(test_labels, pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "_ctHBipRihzO",
        "outputId": "b7be65c3-b930-4457-ad68-c15b70d23140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Micro-precision is  0.6999999999999998\n"
          ]
        }
      ],
      "source": [
        "print(\"Micro-precision is \",(0.82+0.73+0.57+0.67+0.61+0.8)/6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZT2zxcUcl8dP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Deep Learning model - Restaurant Dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
